Building DAG of jobs...
Using shell: /cvmfs/soft.computecanada.ca/gentoo/2020/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	PURITY
	1	all
	2

[Fri Aug  6 13:44:53 2021]
rule PURITY:
    output: /home/emiliano/projects/def-cdesouza/Lab/AIR+VM+PURITY_LaManno.txt
    jobid: 1

[Fri Aug  6 13:44:53 2021]
Error in rule PURITY:
    jobid: 1
    output: /home/emiliano/projects/def-cdesouza/Lab/AIR+VM+PURITY_LaManno.txt
    shell:
        Rscript config[SOFTWARE][PURITY] --output_directory OUTDIR --preprocessed_input_directory PREPROCESS_DIR --true_cluster_input_directory TRUE_DIR --sc3_cluster_input_directory config[DIRECTORIES][SC3_CLUSTER] --seurat_cluster_input_directory config[DIRECTORIES][SEURAT_CLUSTER] --giniclust_cluster_input_directory config[DIRECTORIES][GINICLUST_CLUSTER] --backspin_cluster_input_directory /config[DIRECTORIES][BACKSPIN_CLUSTER] --name_dataset config[DATA_NAME] 
        (exited with non-zero exit code)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /project/6052548/Lab/MRNA_pipe/Pipe/Snakemake/Visualize/.snakemake/log/2021-08-06T134452.884744.snakemake.log
